{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get weights from last layer of attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from module.evaluate import load_dev_labels, get_metrics\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from model.highlight_ha import HierarchicalAttPredictorHL\n",
    "from config.basic_config import configs as config\n",
    "from torchmoji.global_variables import PRETRAINED_PATH, VOCAB_PATH\n",
    "import random\n",
    "from module.preprocessor import EnglishPreProcessor\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "import json\n",
    "from torchmoji.sentence_tokenizer import SentenceTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from module import create_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load parameters as defined in confit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "EMAI_PAD_LEN = config['train']['EMAI_PAD_LEN']\n",
    "EMOJ_SENT_PAD_LEN = config['train']['EMOJ_SENT_PAD_LEN']\n",
    "SENT_PAD_LEN = config['train']['SENT_PAD_LEN']\n",
    "SENT_EMB_DIM = config['model']['SENT_EMB_DIM']\n",
    "learning_rate = config['train']['learning_rate']\n",
    "FILL_VOCAB = config['train']['FILL_VOCAB']\n",
    "BATCH_SIZE = config['train']['BATCH_SIZE']\n",
    "\n",
    "SENT_HIDDEN_SIZE = config['model']['SENT_HIDDEN_SIZE']\n",
    "CTX_LSTM_DIM = config['model']['CTX_LSTM_DIM']\n",
    "\n",
    "CLIP = config['train']['CLIP']\n",
    "EARLY_STOP_PATIENCE = config['train']['EARLY_STOP_PATIENCE']\n",
    "LAMBDA1 = config['train']['LAMBDA1']\n",
    "LAMBDA2 = config['train']['LAMBDA2']\n",
    "FLAT = config['train']['FLAT']\n",
    "GAMMA = config['train']['GAMMA']\n",
    "# fix random seeds to ensure replicability\n",
    "RANDOM_SEED = config['train']['RANDOM_SEED']\n",
    "NUM_OF_VOCAB = config['train']['NUM_OF_VOCAB']\n",
    "\n",
    "GLOVE_EMB_PATH = config['emb']['glove_path']\n",
    "bert_vocab_path = config['emb']['bert_vocab_path']\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20003/20003 [00:00<00:00, 377398.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading glove\n",
      "15614 of 20003 found coverage 0.7805829125631155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessor = EnglishPreProcessor()\n",
    "tokenizer = BertTokenizer(vocab_file=bert_vocab_path, do_lower_case=True)\n",
    "\n",
    "print('Tokenizing using dictionary from {}'.format(VOCAB_PATH))\n",
    "with open(VOCAB_PATH, 'r') as f:\n",
    "    vocabulary = json.load(f)\n",
    "emoji_st = SentenceTokenizer(vocabulary, EMOJ_SENT_PAD_LEN)\n",
    "\n",
    "word2id_path = config['infer']['word2id']\n",
    "id2word_path = config['infer']['id2word']\n",
    "\n",
    "with open(word2id_path, 'rb') as w:\n",
    "    word2id = pkl.load(w)\n",
    "with open(id2word_path, 'rb') as i:\n",
    "    id2word = pkl.load(i)\n",
    "num_of_vocab = len(word2id)\n",
    "\n",
    "emb = create_data.build_embedding(id2word, GLOVE_EMB_PATH, num_of_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Attention model without last layer\n",
    "### and load weights from the fully trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for embed.weight\n",
      "Loading weights for lstm_0.weight_ih_l0\n",
      "Loading weights for lstm_0.weight_hh_l0\n",
      "Loading weights for lstm_0.bias_ih_l0\n",
      "Loading weights for lstm_0.bias_hh_l0\n",
      "Loading weights for lstm_0.weight_ih_l0_reverse\n",
      "Loading weights for lstm_0.weight_hh_l0_reverse\n",
      "Loading weights for lstm_0.bias_ih_l0_reverse\n",
      "Loading weights for lstm_0.bias_hh_l0_reverse\n",
      "Loading weights for lstm_1.weight_ih_l0\n",
      "Loading weights for lstm_1.weight_hh_l0\n",
      "Loading weights for lstm_1.bias_ih_l0\n",
      "Loading weights for lstm_1.bias_hh_l0\n",
      "Loading weights for lstm_1.weight_ih_l0_reverse\n",
      "Loading weights for lstm_1.weight_hh_l0_reverse\n",
      "Loading weights for lstm_1.bias_ih_l0_reverse\n",
      "Loading weights for lstm_1.bias_hh_l0_reverse\n",
      "Loading weights for attention_layer.attention_vector\n",
      "Ignoring weights for output_layer.0.weight\n",
      "Ignoring weights for output_layer.0.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HierarchicalAttPredictorHL(\n",
       "  (deepmoji_model): TorchMoji(\n",
       "    (embed): Embedding(50000, 256)\n",
       "    (embed_dropout): Dropout2d(p=0.2)\n",
       "    (lstm_0): LSTMHardSigmoid(256, 512, batch_first=True, bidirectional=True)\n",
       "    (lstm_1): LSTMHardSigmoid(1024, 512, batch_first=True, bidirectional=True)\n",
       "    (attention_layer): AttentionOneParaPerChan(2304)\n",
       "    (final_dropout): Dropout2d(p=0.2)\n",
       "  )\n",
       "  (deepmoji2linear): Linear(in_features=2304, out_features=300, bias=True)\n",
       "  (a_lstm): LSTM(1324, 1000, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (a_self_attention): AttentionOneParaPerChan(2000)\n",
       "  (context_lstm): LSTM(4304, 100, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (ctx_self_attention): AttentionOneParaPerChan(200)\n",
       "  (embeddings): Embedding(20003, 300, padding_idx=0)\n",
       "  (context_to_emo): Linear(in_features=100, out_features=2, bias=True)\n",
       "  (drop_out): Dropout(p=0.2)\n",
       "  (out2label): Linear(in_features=200, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HierarchicalAttPredictorHL(SENT_EMB_DIM, SENT_HIDDEN_SIZE, CTX_LSTM_DIM, num_of_vocab, SENT_PAD_LEN , id2word, USE_ELMO=True, ADD_LINEAR=False) \n",
    "model.load_embedding(emb)\n",
    "model.deepmoji_model.load_specific_weights(PRETRAINED_PATH, exclude_names=['output_layer'])  \n",
    "full_model = torch.load('/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth')\n",
    "# model.load_state_dict(full_model.state_dict)  \n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get final_test to try out how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_file = '/data/SuperMod/final_test.csv'\n",
    "final_test_data_list = create_data.load_data_context(data_path=final_test_file, is_train=False)\n",
    "\n",
    "final_test_data_set = create_data.TestDataSet(final_test_data_list, EMAI_PAD_LEN, SENT_PAD_LEN, word2id, id2word, emoji_st, use_unk=False)\n",
    "final_test_data_loader = DataLoader(final_test_data_set, batch_size= BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all , this was my idea .',\n",
       " 'i have been suggesting this idea for three months , but no one was listening .',\n",
       " 'what tina suggested was far from realistic .',\n",
       " 'even if we were able to implement her idea , it would be a waste of time']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_data_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_list_test = []\n",
    "final_pred_weights = []\n",
    "sents = []\n",
    "model.cuda()\n",
    "for i, (a, a_len, emoji_a) in enumerate(final_test_data_loader):\n",
    "        \n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            out, weight = model(a.cuda(), a_len, emoji_a.cuda())\n",
    "            \n",
    "            sents.append(emoji_a.cpu().numpy())\n",
    "            \n",
    "                   \n",
    "            final_pred_weights.append(weight.cpu().numpy())\n",
    "\n",
    "            final_pred_list_test.append(out.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(final_pred_weights[0][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_sent_and_weights (ind_of_sample):\n",
    "    \n",
    "#     word_list = final_test_data_list[ind_of_sample]\n",
    "#     weight_list = final_pred_weights[0][ind_of_sample]\n",
    "    \n",
    "#     if len(word_list) > 10:\n",
    "#         word_list = word_list[:10]\n",
    "#     elif len(word_list) < 10:\n",
    "#         weight_list = weight_list[:len(word_list)]\n",
    "#         sum_new_weights = sum(weight_list)\n",
    "#         weight_list = weight_list/sum(weight_list)\n",
    "        \n",
    "        \n",
    "#     for words, score in zip(word_list, weight_list):\n",
    "        \n",
    "#         print(score, words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sent_and_weights (ind_of_sample):\n",
    "    \n",
    "    word_list = final_test_data_list[ind_of_sample]\n",
    "    weight_list = final_pred_weights[0][ind_of_sample]\n",
    "    \n",
    "    if len(word_list) > 10:\n",
    "        word_list = word_list[:10]\n",
    "    elif len(word_list) < 10:\n",
    "        weight_list = weight_list[:len(word_list)]\n",
    "        sum_new_weights = sum(weight_list)\n",
    "        weight_list = weight_list/sum(weight_list)\n",
    "        tox_ind = np.argsort(weight_list)\n",
    "        \n",
    "    for words, score in zip(word_list, tox_ind):\n",
    "        \n",
    "        print(score, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 all , this was my idea .\n",
      "1 i have been suggesting this idea for three months , but no one was listening .\n",
      "2 what tina suggested was far from realistic .\n",
      "3 even if we were able to implement her idea , it would be a waste of time\n"
     ]
    }
   ],
   "source": [
    "print_sent_and_weights(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 even though what you have said is meaningless , i will do what you say\n"
     ]
    }
   ],
   "source": [
    "print_sent_and_weights(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 feel free to pass this along to hr .\n",
      "1 keep them in the loop for all i care .\n",
      "2 may as well do it early .\n",
      "4 you are a misogynist and a terrible human .\n",
      "3 i will keep hounding you until one of us is fired .\n"
     ]
    }
   ],
   "source": [
    "print_sent_and_weights(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4999581 let ’ s not involve jim in this .\n",
      "0.5000419 he tend to talk a lot during meetings and make them unnecessarily long .\n"
     ]
    }
   ],
   "source": [
    "print_sent_and_weights(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14253521 someone please explain to her , who was recently called racist by those in her own party , that there is nothing wrong with bringing out the very obvious fact that he has done a very poor job for his district and the city .\n",
      "0.14285633 just take a look , the facts speak far louder than words !\n",
      "0.14296398 the dem always play the race card , when in fact they have done so little for our nation ’ s great people .\n",
      "0.14309411 now , lowest unemployment in u .\n",
      "0.14286453 s .\n",
      "0.14271094 history , and only getting better .\n",
      "0.14297494 he has failed badly !\n"
     ]
    }
   ],
   "source": [
    "print_sent_and_weights(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1006, 0.1007, 0.1007, 0.1005, 0.1003, 0.1002, 0.1001, 0.0998, 0.0992,\n",
       "        0.0979])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred_weights[0][35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_weights[0][28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0997, 0.1000, 0.1002, 0.1006, 0.1006, 0.1008, 0.1007, 0.1002, 0.0994,\n",
       "        0.0978])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred_weights[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all , this was my idea .',\n",
       " 'i have been suggesting this idea for three months , but no one was listening .',\n",
       " 'what tina suggested was far from realistic .',\n",
       " 'even if we were able to implement her idea , it would be a waste of time']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_data_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"it ' s all their fault we failed .\",\n",
       " 'no idea why anyone would hire pathetic losers like them .']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_data_list[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all , i understand we are deciding on an idea .',\n",
       " 'i recommend going with option a .',\n",
       " 'as i mentioned in our meeting , this option is realistic and easy to implement .',\n",
       " 'we can get it up and running quickly .',\n",
       " 'tina suggested option b .',\n",
       " 'that was a viable option as well .',\n",
       " 'option b would work better if we are not under such tight time pressure .']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_data_list[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get a highlight test to see how well it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_test_file = '/data/SuperMod/highlight_test.csv'\n",
    "highlight_test_data_list = create_data.load_data_context(data_path=highlight_test_file, is_train=False)\n",
    "\n",
    "highlight_test_data_set = create_data.TestDataSet(highlight_test_data_list, EMAI_PAD_LEN, SENT_PAD_LEN, word2id, id2word, emoji_st, use_unk=False)\n",
    "highlight_test_data_loader = DataLoader(highlight_test_data_set, batch_size= BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_pred_list_test = []\n",
    "highlight_pred_weights = []\n",
    "\n",
    "model.cuda()\n",
    "for i, (a, a_len, emoji_a) in enumerate(highlight_test_data_loader):\n",
    "        \n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            out, weight = model(a.cuda(), a_len, emoji_a.cuda())            \n",
    "                   \n",
    "            highlight_pred_weights.append(weight.cpu().numpy())\n",
    "\n",
    "            highlight_pred_list_test.append(out.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sent_and_weights_hl (ind_of_sample):\n",
    "    \n",
    "    word_list = highlight_test_data_list[ind_of_sample]\n",
    "    weight_list = highlight_pred_weights[0][ind_of_sample]\n",
    "    \n",
    "    if len(word_list) > 10:\n",
    "        word_list = word_list[:10]\n",
    "    elif len(word_list) < 10:\n",
    "        weight_list = weight_list[:len(word_list)]\n",
    "        sum_new_weights = sum(weight_list)\n",
    "        weight_list = weight_list/sum(weight_list)\n",
    "    \n",
    "    weight_list = np.asarray(weight_list)\n",
    "    word_list =  np.asarray(word_list)\n",
    "    \n",
    "    tox_ind = np.argsort(weight_list)\n",
    "\n",
    "    rank = [np.where(tox_ind ==  i)[0][0] for i in range(len(tox_ind))]\n",
    "    \n",
    "    print(weight_list)\n",
    "    print(tox_ind)\n",
    "    print(rank)\n",
    "\n",
    "        \n",
    "\n",
    "    for i, (words,  score, r) in enumerate(zip(word_list, weight_list, rank )):\n",
    "\n",
    "        print(r, round(score,4), words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19918515 0.20000385 0.2001275  0.20010762 0.20057593]\n",
      "[0 1 3 2 4]\n",
      "[0, 1, 3, 2, 4]\n",
      "0 0.1992 what tina suggested was far from realistic .\n",
      "1 0.2 it would be a waste of time .\n",
      "3 0.2001 i have been suggesting this idea for three months .\n",
      "2 0.2001 no one was listening .\n",
      "4 0.2006 this was my idea .\n"
     ]
    }
   ],
   "source": [
    "print_sent_and_weights_hl(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19842854 0.19907728 0.19987172 0.2006671  0.20195535]\n",
      "[0 1 2 3 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "0 0.1984 this was my idea .\n",
      "1 0.1991 i have been suggesting this idea for three months .\n",
      "2 0.1999 no one was listening .\n",
      "3 0.2007 what tina suggested was far from realistic .\n",
      "4 0.202 it would be a waste of time .\n"
     ]
    }
   ],
   "source": [
    "print_sent_and_weights_hl(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49925917 0.5007408 ]\n",
      "[0 1]\n",
      "[0, 1]\n",
      "0 0.4993 i will do what you say .\n",
      "1 0.5007 even though what you have said is meaningless .\n"
     ]
    }
   ],
   "source": [
    "print_sent_and_weights_hl(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5000361  0.49996385]\n",
      "[1 0]\n",
      "[1, 0]\n",
      "1 0.5 even though what you have said is meaningless .\n",
      "0 0.5 i will do what you say\n"
     ]
    }
   ],
   "source": [
    "print_sent_and_weights_hl(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49869844 0.5013015 ]\n",
      "[0 1]\n",
      "[0, 1]\n",
      "0 0.4987 i have work to do .\n",
      "1 0.5013 stop bothering me .\n"
     ]
    }
   ],
   "source": [
    "print_sent_and_weights_hl(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4996464 0.5003536]\n",
      "[0 1]\n",
      "[0, 1]\n",
      "0 0.4996 stop bothering me .\n",
      "1 0.5004 i have work to do .\n"
     ]
    }
   ],
   "source": [
    "print_sent_and_weights_hl(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49902079 0.5009792 ]\n",
      "[0 1]\n",
      "[0, 1]\n",
      "0 0.499 i have work to do .\n",
      "1 0.501 stop wasting my time with worthless ideas .\n"
     ]
    }
   ],
   "source": [
    "print_sent_and_weights_hl(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4996745 0.5003255]\n",
      "[0 1]\n",
      "[0, 1]\n",
      "0 0.4997 stop wasting my time with worthless ideas .\n",
      "1 0.5003 i have work to do .\n"
     ]
    }
   ],
   "source": [
    "print_sent_and_weights_hl(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25004327 0.24952266 0.249835   0.25059903]\n",
      "[1 2 0 3]\n",
      "[2, 0, 1, 3]\n",
      "2 0.25 this is completely idiotic .\n",
      "0 0.2495 the last idea is great .\n",
      "1 0.2498 this is never going to work .\n",
      "3 0.2506 i will think of another one .\n"
     ]
    }
   ],
   "source": [
    "print_sent_and_weights_hl(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24978505 0.2500586  0.24971727 0.25043914]\n",
      "[2 0 1 3]\n",
      "[1, 2, 0, 3]\n",
      "1 0.2498 i will think of another one .\n",
      "2 0.2501 this is completely idiotic .\n",
      "0 0.2497 the last idea is great .\n",
      "3 0.2504 this is never going to work .\n"
     ]
    }
   ],
   "source": [
    "print_sent_and_weights_hl(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "1. Later sentences tend to receive higher score\n",
    "2. It makes sense because later sentences are built on prior ones\n",
    "3. And earlier sentences can change meaning of later sentences. E.g. I have work to do sounds fine as first sentence, but after saying stop wasting my time, I have work to do becomes toxic. \n",
    "\n",
    "This shows that even though we kind of flags the emotion in our sentences, this is not always accurate in finding out the 'toxic sentence' - probably the downside of capturing context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to .py and test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 375859.76it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "Loading weights for embed.weight\n",
      "Loading weights for lstm_0.weight_ih_l0\n",
      "Loading weights for lstm_0.weight_hh_l0\n",
      "Loading weights for lstm_0.bias_ih_l0\n",
      "Loading weights for lstm_0.bias_hh_l0\n",
      "Loading weights for lstm_0.weight_ih_l0_reverse\n",
      "Loading weights for lstm_0.weight_hh_l0_reverse\n",
      "Loading weights for lstm_0.bias_ih_l0_reverse\n",
      "Loading weights for lstm_0.bias_hh_l0_reverse\n",
      "Loading weights for lstm_1.weight_ih_l0\n",
      "Loading weights for lstm_1.weight_hh_l0\n",
      "Loading weights for lstm_1.bias_ih_l0\n",
      "Loading weights for lstm_1.bias_hh_l0\n",
      "Loading weights for lstm_1.weight_ih_l0_reverse\n",
      "Loading weights for lstm_1.weight_hh_l0_reverse\n",
      "Loading weights for lstm_1.bias_ih_l0_reverse\n",
      "Loading weights for lstm_1.bias_hh_l0_reverse\n",
      "Loading weights for attention_layer.attention_vector\n",
      "Ignoring weights for output_layer.0.weight\n",
      "Ignoring weights for output_layer.0.bias\n",
      "\n",
      "sample 1\n",
      "0 what tina suggested was far from realistic .\n",
      "1 it would be a waste of time .\n",
      "3 i have been suggesting this idea for three months .\n",
      "2 no one was listening .\n",
      "4 this was my idea .\n",
      "\n",
      "sample 2\n",
      "0 this was my idea .\n",
      "1 i have been suggesting this idea for three months .\n",
      "2 no one was listening .\n",
      "3 what tina suggested was far from realistic .\n",
      "4 it would be a waste of time .\n",
      "\n",
      "sample 3\n",
      "0 i will do what you say .\n",
      "1 even though what you have said is meaningless .\n",
      "\n",
      "sample 4\n",
      "1 even though what you have said is meaningless .\n",
      "0 i will do what you say\n",
      "\n",
      "sample 5\n",
      "0 i have work to do .\n",
      "1 stop bothering me .\n",
      "\n",
      "sample 6\n",
      "0 stop bothering me .\n",
      "1 i have work to do .\n",
      "\n",
      "sample 7\n",
      "0 i have work to do .\n",
      "1 stop wasting my time with worthless ideas .\n",
      "\n",
      "sample 8\n",
      "0 stop wasting my time with worthless ideas .\n",
      "1 i have work to do .\n",
      "\n",
      "sample 9\n",
      "2 this is completely idiotic .\n",
      "0 the last idea is great .\n",
      "1 this is never going to work .\n",
      "3 i will think of another one .\n",
      "\n",
      "sample 10\n",
      "1 i will think of another one .\n",
      "2 this is completely idiotic .\n",
      "0 the last idea is great .\n",
      "3 this is never going to work .\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python get_highlight_ha.py -test_path '/data/SuperMod/highlight_test.csv'  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 372338.50it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "1it [01:15, 75.02s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path '/data/SuperMod/highlight_test.csv' -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_weight.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(10,)\n",
      "True Positives per class :  10\n",
      "False Positives per class :  0\n",
      "False Negatives per class :  0\n",
      "Accuracy : 1.0000, Precision : 1.000, Recall : 1.000, F1 : 1.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from module.evaluate import load_dev_labels, get_metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "org_data = pd.read_csv('/data/SuperMod/highlight_test.csv' )\n",
    "\n",
    "\n",
    "with open('/data/SuperMod/infer_result_weight.pkl', 'rb') as w:\n",
    "    scores = pkl.load(w)\n",
    "get_metrics(np.asarray(org_data.toxicity), np.asarray(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83520013 0.8944876  0.59026694 0.5193461  0.90878546 0.9376847\n",
      " 0.9223477  0.8613115  0.92596424 0.9394643 ]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
